<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<title>顔に芋を貼るAI</title>
<style>
  body,main {
    font-family: sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 1rem;
    background: #f4f4f4;
  }
  body {
    min-height: 95vh;
    display: flex;
    flex-direction: column;
  }
  main{
    flex:1;
    padding: 2rem;
  }
  canvas {
    border: 1px solid #aaa;
    border-radius: 8px;
    max-width: 90vw;
  }
  #controls {
    display: flex;
    gap: 1rem;
  }
  button {
    padding: 0.6rem 1.2rem;
    font-size: 1rem;
    border: none;
    border-radius: 6px;
    background: #0078d7;
    color: white;
    cursor: pointer;
  }
  button:disabled {
    background: #999;
    cursor: not-allowed;
  }
  /* HTML: <div class="loader"></div> */
  .loader {
    width: 50px;
    aspect-ratio: 1;
    border-radius: 50%;
    border: 8px solid;
    border-color: #000 #0000;
    animation: l1 1s infinite;
  }
  @keyframes l1 {to{transform: rotate(.5turn)}}
</style>
<!-- tensorflowとblazefaceのインポート  順番を変えないこと -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> 
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
</head>
<body>
  <main>
    <div class="loader"></div>
    <p2 class="loadText">モデルロード中</p2>
    <h2>顔に芋を貼り付けよう</h2>

    <input type="file" id="fileInput" accept="image/*">
    <canvas id="canvas" style="max-height: 90vh;"></canvas>

    <div id="controls">
      <button id="processBtn" disabled>顔検出＋合成</button>
      <button id="downloadBtn" disabled>ダウンロード</button>
    </div>
  </main>

  <script>
    const fileInput = document.getElementById("fileInput");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const processBtn = document.getElementById("processBtn");
    const downloadBtn = document.getElementById("downloadBtn");
    const loadingCss = document.getElementsByClassName("loader")[0];
    const loadingText = document.getElementsByClassName("loadText")[0];

    let image = new Image();
    let model;
    let overlayImage;

    // 🔹 モデルとオーバーレイ画像を事前にロード
    async function init() {
      console.log("モデル読み込み中...");
      model = await blazeface.load(); // 自動で軽量モデルを読み込む
      overlayImage = await loadOverlayImage("imo.png");
      console.log("モデルとオーバーレイ画像読み込み完了");
      loadingCss.style = "display:none;";
      loadingText.style = "display:none;";
    }

    // 🔹 overlay画像を非同期ロード
    async function loadOverlayImage(url) {
      const img = new Image();
      img.crossOrigin = "anonymous";
      return new Promise((resolve, reject) => {
        img.onload = () => resolve(img);
        img.onerror = reject;
        img.src = url;
      });
    }

    // 🔹 画像選択イベント
    fileInput.addEventListener("change", (e) => {
      const file = e.target.files[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = () => {
        image.src = reader.result;
      };
      reader.readAsDataURL(file);
    });

    // 🔹 画像がロードされたらCanvasに描画
    image.onload = () => {
      canvas.width = image.width;
      canvas.height = image.height;
      ctx.drawImage(image, 0, 0);
      processBtn.disabled = false;
    };

    // 🔹 顔検出＋合成処理
    processBtn.addEventListener("click", async () => {
    if (!model || !overlayImage) return;
    loadingCss.style = "";
    loadingText.style = "";
    loadingText.innerHTML = "画像を処理中";
    const predictions = await model.estimateFaces(image, false);
    // 元画像を再描画
    ctx.drawImage(image, 0, 0);
    console.log(predictions);

    predictions.forEach(pred => {
        const [x_start, y_start] = pred.topLeft;
        const [x_end, y_end] = pred.bottomRight;

        // 検出された幅と高さ
        const w_orig = x_end - x_start;
        const h_orig = y_end - y_start;
        
        // ----------------------------------------------------
        // ✨ 調整ロジック ✨
        // ----------------------------------------------------
        
        // 1. パディング（拡大）を設定
        // 幅を約20%拡大するパディング
        const W_PADDING_RATIO = 0.30; 
        const H_PADDING_RATIO = 0.40; // 縦はもっと大きく拡大し、上にずらす
        
        // 拡大後の新しい幅
        const w_new = w_orig * (1 + W_PADDING_RATIO);
        // 拡大後の新しい高さ
        const h_new = h_orig * (1 + H_PADDING_RATIO); 

        // 2. 新しい描画開始位置の計算
        // x座標を中央寄せで調整
        const x_new = x_start - (w_new - w_orig) / 2;
        // y座標を上に調整 (例: 検出された開始位置から上に10%ずらす)
        // 💡 BlazeFaceは鼻のあたりを検出するため、上に大きくパディングが必要です
        const y_new = y_start - h_orig * 0.3; // 検出高さの15%分上に移動させる

        // 3. 描画
        // 新しい位置とサイズで合成画像をdrawImage
        ctx.drawImage(overlayImage, x_new, y_new, w_new, h_new);
    });
    loadingCss.style = "display:none;";
    loadingText.style = "display:none;";

    downloadBtn.disabled = false;
    });

    // 🔹 加工画像をダウンロード
    downloadBtn.addEventListener("click", () => {
      const a = document.createElement("a");
      a.href = canvas.toDataURL("image/png");
      a.download = "processed.png";
      a.click();
    });

    window.onload = init; // 起動時にモデルロード
  </script>
  <footer style="width: 100%;">
    <hr>
    <p style="text-align: center;color: #777;">© 2025 PotatoTimeKun<br>常識の範囲内でお使いください。<br>MIT Licence</p>
  </footer>
</body>
</html>
